{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ba93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import albumentations as A\n",
    "import torch.multiprocessing as mp\n",
    "from  datetime import datetime \n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import torch.utils.data as DataLoader\n",
    "\n",
    "from models import Person_Activity_Temporal\n",
    "\n",
    "from dataloader import Person , person_activity_labels\n",
    "from eval_utils import get_f1_score , plot_confusion_matrix\n",
    "from helper_utils import load_config , save_checkpoint_model , load_checkpoint_model , setup_logging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLine_7A_Trainer():\n",
    "    def __init__(self , config_file_path , Project_root):\n",
    "        self.config = load_config(config_file_path)\n",
    "        self.Project_root = Project_root\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        self.exp_dir  = os.path.join(\n",
    "            f\"{self.Project_root} / training /baseline7a / {self.config['experiment']['output_dir']}\" , \n",
    "            f\"{self.config['experiment']['name']}_V{self.config['experiment']['version']}_{timestamp}\"\n",
    "        )\n",
    "        os.makedirs(self.exp_dir , exist_ok=True)\n",
    "        self.set_seed(self.config['experiment']['seed'])\n",
    "\n",
    "        self.model = Person_Activity_Temporal(\n",
    "            num_classes= self.config['model']['num_classes']['person_activity'],\n",
    "            hidden_size= self.config['model']['hyper_param']['person_activity']['hidden_size'] , \n",
    "            num_layers=self.config['model']['hyper_param']['person_activity']['num_layers']\n",
    "            ).to(self.device)\n",
    "        \n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters() , \n",
    "            lr=self.config['training']['person_activity']['learning_rate'] , \n",
    "            weight_decay=self.config['training']['person_activity']['weight_decay']\n",
    "        )\n",
    "\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, \n",
    "            mode='min', \n",
    "            factor=0.1,\n",
    "            patience=0.3, \n",
    "            verbose=True\n",
    "        )\n",
    "        self.scaler = GradScaler()\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.logger = setup_logging(self.exp_dir)\n",
    "        self.writer = SummaryWriter(log_dir=os.path.join(self.exp_dir, 'tensorboard'))\n",
    "\n",
    "        self.train_loader, self.val_loader = self.prepare_data()\n",
    "        self.class_names = self.config['model']['num_classes_label']['person_activity']\n",
    "        config_save_file = os.path.join(self.exp_dir , 'config.yaml')\n",
    "        with open(config_save_file , 'w') as f:\n",
    "            yaml.dump(self.config , f)\n",
    "        self.logger.info(f\"Configuration saved to {config_save_file}\")\n",
    "\n",
    "\n",
    "    def concat(self , batch):\n",
    "        clips, labels = zip(*batch)  \n",
    "    \n",
    "        max_bboxes = 12  \n",
    "        padded_clips = []\n",
    "        padded_labels = []\n",
    "\n",
    "        for clip, label in zip(clips, labels) :\n",
    "            num_bboxes = clip.size(0)\n",
    "            if num_bboxes < max_bboxes:\n",
    "                clip_padding = torch.zeros((max_bboxes - num_bboxes, clip.size(1), clip.size(2), clip.size(3), clip.size(4)))\n",
    "                label_padding = torch.zeros((max_bboxes - num_bboxes, label.size(1), label.size(2)))\n",
    "                \n",
    "                clip = torch.cat((clip, clip_padding), dim=0)\n",
    "                label = torch.cat((label, label_padding), dim=0)\n",
    "                \n",
    "            padded_clips.append(clip)\n",
    "            padded_labels.append(label)\n",
    "        \n",
    "        padded_clips = torch.stack(padded_clips)\n",
    "        padded_labels = torch.stack(padded_labels)\n",
    "        \n",
    "        padded_labels = padded_labels[:, :, -1, :]  # utils the label of last frame for each player\n",
    "        b, bb, num_class = padded_labels.shape # batch, bbox, num_clases\n",
    "        padded_labels = padded_labels.view(b*bb, num_class)\n",
    "\n",
    "        return padded_clips, padded_labels\n",
    "\n",
    "\n",
    "    \n",
    "    def set_seed(self, seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False  \n",
    "    \n",
    "    def prepare_data(self):\n",
    "        train_transforms = A.Compose([\n",
    "            A.Resize(height=224, width=224),\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3,7)),\n",
    "                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                A.RandomBrightnessContrast(),\n",
    "                A.GaussNoise()\n",
    "\n",
    "            ] , p=0.8),\n",
    "            A.OneOf([A.HorizontalFlip(), A.VerticalFlip()], p=0.05),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "        val_transforms = A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "        train_dataset = Person(\n",
    "            videos_path=self.config['data']['videos_path'],\n",
    "            annot_path=self.config['data']['annot_path'],\n",
    "            split=self.config['data']['video_splits']['train'],\n",
    "            labels=person_activity_labels,\n",
    "            seq=True,\n",
    "            transform=train_transforms\n",
    "           \n",
    "        )\n",
    "\n",
    "        val_dataset = Person(\n",
    "            videos_path=self.config['data']['videos_path'],\n",
    "            annot_path=self.config['data']['annot_path'],\n",
    "            split=self.config['data']['video_splits']['validation'],\n",
    "            labels=person_activity_labels,\n",
    "            seq=True,\n",
    "            transform=val_transforms\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "        self.logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config['training']['person_activity']['batch_size'],\n",
    "            collate_fn=self.concat,\n",
    "            shuffle=True, num_workers=4, pin_memory=True\n",
    "            )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config['training']['person_activity']['batch_size'],\n",
    "            collate_fn=self.concat,\n",
    "            shuffle=False, num_workers=4, pin_memory=True\n",
    "            )\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def validate(self , epoch):\n",
    "        self.model.eval()\n",
    "        total_loss  , correct  , total = 0.0 , 0.0 , 0.0\n",
    "        y_true , y_pred = [] , []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs , targets in self.val_loader:\n",
    "                inputs , targets  =  inputs.to(self.device) , targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                predicted = outputs.argmax(1)\n",
    "                target_class = targets.argmax(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(target_class).sum().item()\n",
    "\n",
    "                y_true.extend(target_class.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "        f1_score = get_f1_score(y_true, y_pred, average=\"weighted\")\n",
    "        self.writer.add_scalar('Validation/Loss', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Validation/Accuracy', accuracy, epoch)\n",
    "        self.writer.add_scalar('Validation/F1Score', f1_score, epoch)\n",
    "        self.writer.add_figure('Validation/ConfusionMatrix', plot_confusion_matrix( y_true, y_pred, class_names = self.config[\"model\"]['num_classes_label']['person_activity'] , save_path = \"/kaggle/working/\"))\n",
    "\n",
    "        self.logger.info(f\"Epoch {epoch} | Valid Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}% | F1 Score: {f1_score:.4f}\")\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def train(self , checkpoint_path=None):\n",
    "        if checkpoint_path:\n",
    "            self.model, self.optimizer, self.loaded_config, self.exp_dir, self.start_epoch = load_checkpoint_model(checkpoint_path, self.model, self.optimizer, self.device)\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            self.exp_dir = os.path.join(\n",
    "            f\"{self.Project_Root}/training/baseline7a/{self.config['experiment']['output_dir']}\",\n",
    "            f\"{self.config['experiment']['name']}_V{self.config['experiment']['version']}_{timestamp}\"\n",
    "        )\n",
    "            os.makedirs(self.exp_dir, exist_ok=True)\n",
    "            self.logger = setup_logging(self.exp_dir)\n",
    "            \n",
    "            if(self.loaded_config):\n",
    "                # config = loaded_config\n",
    "                self.logger.info(f\"Resumed training from epoch {self.start_epoch}\")\n",
    "\n",
    "        else:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            self.exp_dir = os.path.join(\n",
    "            f\"{self.Project_root}/training/baseline7a/{self.config['experiment']['output_dir']}\",\n",
    "            f\"{self.config['experiment']['name']}_V{self.config['experiment']['version']}_{timestamp}\"\n",
    "            )\n",
    "            os.makedirs(self.exp_dir, exist_ok=True)\n",
    "            self.logger = setup_logging(self.exp_dir)\n",
    "            \n",
    "            \n",
    "        self.logger.info(\"Starting training...\")\n",
    "        \n",
    "        for epoch in range(self.config['training']['person_activity']['epochs']):\n",
    "            self.model.train()\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0  \n",
    "            self.logger.info(f\"Epoch {epoch + 1}/{self.config['training']['person_activity']['epochs']}\")\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                with autocast(dtype=torch.float16):\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, labels)\n",
    "\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                predicted_classes = preds.argmax(dim=1)\n",
    "                true_classes = labels.argmax(dim=1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted_classes == true_classes).sum().item()\n",
    "                if batch_idx % 100 == 0:\n",
    "                    acc = total_correct / total_samples\n",
    "                    self.logger.info(f\"Batch {batch_idx}/{len(self.train_loader)} - Loss: {loss.item():.4f} - Accuracy: {acc:.4f}\")\n",
    "\n",
    "            avg_loss = total_loss / len(self.train_loader)\n",
    "            avg_accuracy = 100. * total_correct / total_samples\n",
    "            self.writer.add_scalar('loss/train', avg_loss, epoch)\n",
    "            self.writer.add_scalar('accuracy/train', avg_accuracy, epoch)\n",
    "\n",
    "            self.logger.info(f\"Epoch {epoch + 1} Summary: Loss: {avg_loss:.4f} | Accuracy: {avg_accuracy:.2f}%\")\n",
    "\n",
    "            val_loss, val_acc = self.validate(epoch)\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            self.writer.add_scalar('Training/LearningRate', current_lr, epoch)\n",
    "            self.logger.info(f\"Current learning rate: {current_lr}\")\n",
    "\n",
    "            save_checkpoint_model(self.model, self.optimizer, epoch, val_acc,  self.exp_dir , self.config)\n",
    "\n",
    "        self.writer.close()\n",
    "        self.save_model()\n",
    "\n",
    "    def save_model(self):\n",
    "        final_model_path = os.path.join(self.exp_dir, 'final_model.pth')\n",
    "        torch.save({\n",
    "            'epoch': self.config['training']['epochs'],\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "        }, final_model_path)\n",
    "        self.logger.info(f\"Training completed. Final model saved to: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270e72d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'H:\\\\Group-Activity-Recognition / training '",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     trainer = \u001b[43mBaseLine_7A_Trainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mH:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGroup-Activity-Recognition\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgroup-activity-recognition\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mconfigs\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mBaseline7.yml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mProject_root\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mH:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGroup-Activity-Recognition\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     trainer.train()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mBaseLine_7A_Trainer.__init__\u001b[39m\u001b[34m(self, config_file_path, Project_root)\u001b[39m\n\u001b[32m      6\u001b[39m timestamp = datetime.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m_\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.exp_dir  = os.path.join(\n\u001b[32m      8\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.Project_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m / training /baseline7a / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mexperiment\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m , \n\u001b[32m      9\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mexperiment\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_V\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mexperiment\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexp_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mself\u001b[39m.set_seed(\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mexperiment\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.model = Person_Activity_Temporal(\n\u001b[32m     15\u001b[39m     num_classes= \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mperson_activity\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     16\u001b[39m     hidden_size= \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mhyper_params\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mperson_activity\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m] , \n\u001b[32m     17\u001b[39m     num_layers=\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mhyper_params\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mperson_activity\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mnum_layers\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m     ).to(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'H:\\\\Group-Activity-Recognition / training '"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trainer = BaseLine_7A_Trainer(\n",
    "        config_file_path=r\"H:\\Group-Activity-Recognition\\group-activity-recognition\\configs\\Baseline7.yml\",\n",
    "        Project_root=r\"H:\\Group-Activity-Recognition\",\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfadc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_activity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
