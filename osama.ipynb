{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609ba93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import albumentations as A\n",
    "import torch.multiprocessing as mp\n",
    "import datetime as datetime \n",
    "import albumentations.pytorch as ToTensorV2\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.utils.tensorboard.writer as SummaryWriter\n",
    "import torch.utils.data as DataLoader\n",
    "\n",
    "from models import Person_Activity_Temporal\n",
    "\n",
    "from dataloader import Person , person_activity_labels\n",
    "from eval_utils import get_f1_score , plot_confusion_matrix\n",
    "from helper_utils import load_config , save_checkpoint_model , load_checkpoint_model , setup_logging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLine_7A_Trainer():\n",
    "    def __init__(self , config_file_path , Project_root):\n",
    "        self.config = load_config(config_file_path)\n",
    "        self.Project_root = Project_root\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        self.exp_dir  = os.path.join(\n",
    "            f\"{self.Project_root} / training /baseline7a / {self.config['experiment']['output_dir']}\" , \n",
    "            f\"{self.config['experiment']['name']}_V{self.config['experiment']['version']}_{timestamp}\"\n",
    "        )\n",
    "        os.makedirs(self.exp_dir , exist_ok=True)\n",
    "        self.set_seed(self.config['experiment']['seed'])\n",
    "\n",
    "        self.model = Person_Activity_Temporal(\n",
    "            num_classes= self.config['model']['num_classes']['person_activity'],\n",
    "            hidden_size= self.config['model']['hyper_params']['person_activity']['hidden_size'] , \n",
    "            num_layers=self.config['model']['hyper_params']['person_activity']['num_layers']\n",
    "            ).to(self.device)\n",
    "        \n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters() , \n",
    "            lr=self.config['training']['person_activity']['learning_rate'] , \n",
    "            weight_decay=self.config['training']['person_activity']['weight_decay']\n",
    "        )\n",
    "\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, \n",
    "            mode='min', \n",
    "            factor=0.1\n",
    "            patience=0.3, \n",
    "            verbose=True\n",
    "        )\n",
    "        self.scaler = GradScaler()\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.logger = setup_logging(self.exp_dir)\n",
    "        self.writer = SummaryWriter(log_dir=os.path.join(self.exp_dir, 'tensorboard'))\n",
    "        self.train_loader, self.val_loader = self.prepare_data()\n",
    "        self.class_names = self.config['model']['num_classes_label']['person_activity']\n",
    "        config_save_file = os.path.join(self.exp_dir , 'config.yaml')\n",
    "        with open(config_save_file , 'w') as f:\n",
    "            yaml.dump(self.config , f)\n",
    "        self.logger.info(f\"Configuration saved to {config_save_file}\")\n",
    "\n",
    "\n",
    "    def concat(self , batch):\n",
    "        clips , labels = zip(*batch)\n",
    "        max_bboxes = 12\n",
    "        padded_clips, padded_labels = [], []\n",
    "\n",
    "        for clip , label in zip(clips , labels):\n",
    "            T, C, H, W = clip.shape[1:]\n",
    "            nb = clip.size(0)\n",
    "            if nb > max_bboxes:\n",
    "                clip = clip[:max_bboxes]\n",
    "                label = label[:max_bboxes]\n",
    "            elif nb < max_bboxes:\n",
    "                pad = max_bboxes - nb\n",
    "                clip_pad = torch.zeros((pad, T, C, H, W), dtype=clip.dtype, device=self.device)\n",
    "                label_pad = torch.full((pad, label.size(1)), -100, dtype=torch.long, device=self.device)\n",
    "                clip = torch.cat([clip, clip_pad], dim=0)\n",
    "                label = torch.cat([label, label_pad], dim=0)\n",
    "\n",
    "            padded_clips.append(clip)   # (max_bboxes, T, C, H, W)\n",
    "            padded_labels.append(label) # (max_bboxes, T)\n",
    "\n",
    "        padded_clips = torch.stack(padded_clips, dim=0)    # (B, max_bboxes, T, C, H, W)\n",
    "        padded_labels = torch.stack(padded_labels, dim=0)  # (B, max_bboxes, T)\n",
    "\n",
    "        padded_labels = padded_labels[:, :, -1]   \n",
    "\n",
    "        # flatten\n",
    "        padded_clips = padded_clips.view(-1, T, C, H, W)   \n",
    "        padded_labels = padded_labels.view(-1)             \n",
    "\n",
    "        return padded_clips, padded_labels\n",
    "    \n",
    "    def set_seed(self, seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False  \n",
    "    \n",
    "    def perpare_data(self):\n",
    "        train_transforms = A.Compose([\n",
    "            A.resize(height=224, width=224),\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3,7)),\n",
    "                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                A.RandomBrightnessContrast(),\n",
    "                A.GaussNoise()\n",
    "\n",
    "            ] , p=0.8),\n",
    "            A.OneOf([A.HorizontalFlip(), A.VerticalFlip()], p=0.05),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "        val_transforms = A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "        train_dataset = Person(\n",
    "            videos_path=self.config['data']['videos_path'],\n",
    "            annot_path=self.config['data']['annot_path'],\n",
    "            split=self.config['data']['video_splits']['train'],\n",
    "            labels=person_activity_labels,\n",
    "             seq=True,\n",
    "            transform=train_transforms\n",
    "           \n",
    "        )\n",
    "\n",
    "        val_dataset = Person(\n",
    "            videos_path=self.config['data']['videos_path'],\n",
    "            annot_path=self.config['data']['annot_path'],\n",
    "            split=self.config['data']['video_splits']['validation'],\n",
    "            labels=person_activity_labels,\n",
    "            seq=True,\n",
    "            transform=val_transforms\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "        self.logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config['training']['person_activity']['batch_size'],\n",
    "            collate_fn=self.concat,\n",
    "            shuffle=True, num_workers=4, pin_memory=True\n",
    "            )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config['training']['person_activity']['batch_size'],\n",
    "            collate_fn=self.concat,\n",
    "            shuffle=False, num_workers=4, pin_memory=True\n",
    "            )\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def validate(self , epoch):\n",
    "        self.model.eval()\n",
    "        total_loss  , correct  , total = 0.0 , 0.0 , 0.0\n",
    "        y_true , y_pred = [] , []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs , targets in self.val_loader:\n",
    "                inputs , targets  =  inputs.to(self.device) , targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                predicted = outputs.argmax(1)\n",
    "                target_class = targets.argmax(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(target_class).sum().item()\n",
    "\n",
    "                y_true.extend(target_class.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "        f1_score = get_f1_score(y_true, y_pred, average=\"weighted\")\n",
    "        self.writer.add_scalar('Validation/Loss', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Validation/Accuracy', accuracy, epoch)\n",
    "        self.writer.add_scalar('Validation/F1Score', f1_score, epoch)\n",
    "        self.writer.add_figure('Validation/ConfusionMatrix', plot_confusion_matrix( y_true, y_pred, class_names = self.config[\"model\"]['num_clases_label']['group_activity'] , save_path = \"/kaggle/working/\"))\n",
    "\n",
    "        self.logger.info(f\"Epoch {epoch} | Valid Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}% | F1 Score: {f1_score:.4f}\")\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def train(self , checkpoint_path=None):\n",
    "        if checkpoint_path:\n",
    "            self.model, self.optimizer, self.loaded_config, self.exp_dir, self.start_epoch = load_checkpoint_model(checkpoint_path, self.model, self.optimizer, self.device)\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            self.exp_dir = os.path.join(\n",
    "            f\"{self.Project_Root}/training/baseline5a/{self.config['experiment']['output_dir']}\",\n",
    "            f\"{self.config['experiment']['name']}_V{self.config['experiment']['version']}_{timestamp}\"\n",
    "        )\n",
    "            os.makedirs(self.exp_dir, exist_ok=True)\n",
    "            self.logger = setup_logging(self.exp_dir)\n",
    "            \n",
    "            if(self.loaded_config):\n",
    "                # config = loaded_config\n",
    "                self.logger.info(f\"Resumed training from epoch {self.start_epoch}\")\n",
    "\n",
    "        else:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            self.exp_dir = os.path.join(\n",
    "            f\"{self.Project_root}/training/baseline5a/{self.config['experiment']['output_dir']}\",\n",
    "            f\"{self.config['experiment']['name']}_V{self.config['experiment']['version']}_{timestamp}\"\n",
    "            )\n",
    "            os.makedirs(self.exp_dir, exist_ok=True)\n",
    "            self.logger = setup_logging(self.exp_dir)\n",
    "            \n",
    "            \n",
    "        self.logger.info(\"Starting training...\")\n",
    "        \n",
    "        for epoch in range(self.config['training']['group_activity']['epochs']):\n",
    "            self.model.train()\n",
    "            total_loss, total_correct, total_samples = 0, 0, 0  \n",
    "            self.logger.info(f\"Epoch {epoch + 1}/{self.config['training']['group_activity']['epochs']}\")\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                with autocast(dtype=torch.float16):\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, labels)\n",
    "\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                predicted_classes = preds.argmax(dim=1)\n",
    "                true_classes = labels.argmax(dim=1)\n",
    "                total_samples += labels.size(0)\n",
    "                total_correct += (predicted_classes == true_classes).sum().item()\n",
    "                if batch_idx % 100 == 0:\n",
    "                    acc = total_correct / total_samples\n",
    "                    self.logger.info(f\"Batch {batch_idx}/{len(self.train_loader)} - Loss: {loss.item():.4f} - Accuracy: {acc:.4f}\")\n",
    "\n",
    "            avg_loss = total_loss / len(self.train_loader)\n",
    "            avg_accuracy = 100. * total_correct / total_samples\n",
    "            self.writer.add_scalar('loss/train', avg_loss, epoch)\n",
    "            self.writer.add_scalar('accuracy/train', avg_accuracy, epoch)\n",
    "\n",
    "            self.logger.info(f\"Epoch {epoch + 1} Summary: Loss: {avg_loss:.4f} | Accuracy: {avg_accuracy:.2f}%\")\n",
    "\n",
    "            val_loss, val_acc = self.validate(epoch)\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            self.writer.add_scalar('Training/LearningRate', current_lr, epoch)\n",
    "            self.logger.info(f\"Current learning rate: {current_lr}\")\n",
    "\n",
    "            save_checkpoint_model(self.model, self.optimizer, epoch, val_acc,  self.exp_dir , self.config)\n",
    "\n",
    "        self.writer.close()\n",
    "        self.save_model()\n",
    "\n",
    "  def save_model(self):\n",
    "        final_model_path = os.path.join(self.exp_dir, 'final_model.pth')\n",
    "        torch.save({\n",
    "            'epoch': self.config['training']['epochs'],\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "        }, final_model_path)\n",
    "        self.logger.info(f\"Training completed. Final model saved to: {final_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_activity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
